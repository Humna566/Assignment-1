{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subcorpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpusroot = \"./Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = PlaintextCorpusReader(corpusroot, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "essayFile = reviews.words('finalEssay.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POL', '222', 'FINAL', 'ESSAY', 'ASSIGNMENT', '?', ...]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essayFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpusroot = \"./Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = PlaintextCorpusReader(corpusroot, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsFile = reviews.words('newsFile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AT', 'AROUND', '7', 'am', 'on', 'a', 'quiet', ...]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpusroot = \"./Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = PlaintextCorpusReader(corpusroot, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakeFile = reviews.words('shakespeare-hamlet-25.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HAMLET', 'DRAMATIS', 'PERSONAE', 'CLAUDIUS', 'king', ...]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakeFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HAMLET'], ['DRAMATIS', 'PERSONAE'], ...]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakeFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POL', '222', 'FINAL', 'ESSAY', 'ASSIGNMENT', '?', ...]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essayFile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lenght of this subcorpus is 6972 words.\n"
     ]
    }
   ],
   "source": [
    "print (\"The lenght of this subcorpus is\",len(essayFile), \"words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AT', 'AROUND', '7', 'am', 'on', 'a', 'quiet', ...]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lenght of this subcorpus is 15844 words.\n"
     ]
    }
   ],
   "source": [
    "print (\"The lenght of this subcorpus is\",len(newsFile), \"words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HAMLET', 'DRAMATIS', 'PERSONAE', 'CLAUDIUS', 'king', ...]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakeFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lenght of this subcorpus is 41190 words.\n"
     ]
    }
   ],
   "source": [
    "print (\"The lenght of this subcorpus is\",len(shakeFile), \"words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data = [essayFile, newsFile, shakeFile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POL', '222', 'FINAL', 'ESSAY', 'ASSIGNMENT', '?', ...]\n",
      "['AT', 'AROUND', '7', 'am', 'on', 'a', 'quiet', ...]\n",
      "['HAMLET', 'DRAMATIS', 'PERSONAE', 'CLAUDIUS', 'king', ...]\n"
     ]
    }
   ],
   "source": [
    "for file in data:\n",
    "    print(file)\n",
    "\n",
    "def lexical_diversity(file):\n",
    "    return len(set(file)) / len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20474627619288058"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(essayFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20474627619288058"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(newsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12337946103423161"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(shakeFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The longest sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakeFile = reviews.sents('shakespeare-hamlet-25.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HAMLET'], ['DRAMATIS', 'PERSONAE'], ...]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakeFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['One', 'speech', 'in', 'it', 'I', 'chiefly', 'loved', ':', \"'\", 'twas', 'Aeneas', \"'\", 'tale', 'to', 'Dido', ';', 'and', 'thereabout', 'of', 'it', 'especially', ',', 'where', 'he', 'speaks', 'of', 'Priam', \"'\", 's', 'slaughter', ':', 'if', 'it', 'live', 'in', 'your', 'memory', ',', 'begin', 'at', 'this', 'line', ':', 'let', 'me', 'see', ',', 'let', 'me', 'see', '--', \"'\", 'The', 'rugged', 'Pyrrhus', ',', 'like', 'the', 'Hyrcanian', 'beast', \",'--\", 'it', 'is', 'not', 'so', ':--', 'it', 'begins', 'with', 'Pyrrhus', ':--', \"'\", 'The', 'rugged', 'Pyrrhus', ',', 'he', 'whose', 'sable', 'arms', ',', 'Black', 'as', 'his', 'purpose', ',', 'did', 'the', 'night', 'resemble', 'When', 'he', 'lay', 'couched', 'in', 'the', 'ominous', 'horse', ',', 'Hath', 'now', 'this', 'dread', 'and', 'black', 'complexion', 'smear', \"'\", 'd', 'With', 'heraldry', 'more', 'dismal', ';', 'head', 'to', 'foot', 'Now', 'is', 'he', 'total', 'gules', ';', 'horridly', 'trick', \"'\", 'd', 'With', 'blood', 'of', 'fathers', ',', 'mothers', ',', 'daughters', ',', 'sons', ',', 'Baked', 'and', 'impasted', 'with', 'the', 'parching', 'streets', ',', 'That', 'lend', 'a', 'tyrannous', 'and', 'damned', 'light', 'To', 'their', 'lord', \"'\", 's', 'murder', ':', 'roasted', 'in', 'wrath', 'and', 'fire', ',', 'And', 'thus', 'o', \"'\", 'er', '-', 'sized', 'with', 'coagulate', 'gore', ',', 'With', 'eyes', 'like', 'carbuncles', ',', 'the', 'hellish', 'Pyrrhus', 'Old', 'grandsire', 'Priam', 'seeks', \".'\"]]\n"
     ]
    }
   ],
   "source": [
    "longest_len = max(len(s) for s in shakeFile)\n",
    "longest = [s for s in shakeFile if len(s) == longest_len]\n",
    "print(longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsFile = reviews.sents('newsFile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AT', 'AROUND', '7', 'am', 'on', 'a', 'quiet', 'Wednesday', 'in', 'August', '2017', ',', 'Marcus', 'Hutchins', 'walked', 'out', 'the', 'front', 'door', 'of', 'the', 'Airbnb', 'mansion', 'in', 'Las', 'Vegas', 'where', 'he', 'had', 'been', 'partying', 'for', 'the', 'past', 'week', 'and', 'a', 'half', '.'], ['A', 'gangly', ',', '6', \"'\", '4', '\",', '23', '-', 'year', '-', 'old', 'hacker', 'with', 'an', 'explosion', 'of', 'blond', '-', 'brown', 'curls', ',', 'Hutchins', 'had', 'emerged', 'to', 'retrieve', 'his', 'order', 'of', 'a', 'Big', 'Mac', 'and', 'fries', 'from', 'an', 'Uber', 'Eats', 'deliveryman', '.'], ...]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['By', 'the', 'next', 'day', ',', 'the', 'representative', 'for', 'Hutchins', \"'\", 'region', 'in', 'the', 'UK', 'parliament', ',', 'Peter', 'Heaton', '-', 'Jones', ',', 'issued', 'a', 'statement', 'expressing', 'his', '“', 'concern', 'and', 'shock', ',”', 'lauding', 'Hutchins', \"'\", 'work', 'on', 'WannaCry', 'and', 'noting', 'that', '“', 'people', 'who', 'know', 'him', 'in', 'Ilfracombe', ',', 'and', 'the', 'wider', 'cyber', 'community', ',', 'are', 'astounded', 'at', 'the', 'allegations', 'against', 'him', '.”', 'Mabbitt', 'found', 'Hutchins', 'a', 'local', 'attorney', 'for', 'his', 'bail', 'hearing', ',', 'and', 'after', 'Hutchins', 'spent', 'a', 'miserable', 'day', 'in', 'a', 'crowded', 'cage', ',', 'his', 'bail', 'was', 'set', 'at', '$', '30', ',', '000', '.']]\n"
     ]
    }
   ],
   "source": [
    "longest_len = max(len(s) for s in newsFile)\n",
    "longest2 = [s for s in newsFile if len(s) == longest_len]\n",
    "print(longest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "essayFile = reviews.sents('finalEssay.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['POL', '222', 'FINAL', 'ESSAY', 'ASSIGNMENT', '?'], ['Humna', 'Khan', 'POL', '222', ':', 'Introduction', 'to', 'Canadian', 'Politics', '?'], ...]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essayFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Journal', 'of', 'International', 'Migration', 'and', 'Integration', ',', '(', '2019', '),', '1', '-', '20', ',', 'DOI', ':', '10', '.', '1007', '/', 's12134', '-', '019', '-', '00693', '-', 'w', ',', '?']]\n"
     ]
    }
   ],
   "source": [
    "longest_len = max(len(s) for s in essayFile)\n",
    "longest3 = [s for s in essayFile if len(s) == longest_len]\n",
    "print(longest3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The top collocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KING CLAUDIUS; QUEEN GERTRUDE; LORD POLONIUS; First Clown; Second\n",
      "Clown; HAMLET ACT; PRINCE FORTINBRAS; Lord Hamlet; First Player; thou\n",
      "hast; Player Queen; good friends; good night; Exeunt ROSENCRANTZ;\n",
      "Enter KING; Player King; Another room; ACT III; III SCENE; wilt thou\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    ">>> text458 = Text(reviews.words('shakespeare-hamlet-25.txt'))\n",
    ">>> text458.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kryptos Logic; Las Vegas; UPAS Kit; kill switch; Los Angeles; law\n",
      "enforcement; Silk Road; remembers thinking; sinkhole domain; legal\n",
      "fund; nine months; impending doom; instant messaging; DDoS attacks;\n",
      "SUV parked; Marcus Hutchins; Royal London; hacker community; Salim\n",
      "Neino; Hutchins says\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    ">>> text458 = Text(reviews.words('newsFile.txt'))\n",
    ">>> text458.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "immigration system; TFW program; https ://; permanent residency;\n",
      "Leonor Cedillio; labor market; Temporary Foreign; International\n",
      "Migration; neoliberal values; social cohesion; food truck; low\n",
      "skilled; temporary foreign; skilled TFW; foreign workers; short term;\n",
      "Economic Class; Factors Influencing; global south; many immigrants\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    ">>> text458 = Text(reviews.words('finalEssay.txt'))\n",
    ">>> text458.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The top ten words that start with each of the vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POL', '222', 'FINAL', 'ESSAY', 'ASSIGNMENT', '?', ...]\n",
      "['his', 'is', 'a', 'group', 'assignment', '.', 'You', ...]\n",
      "['HAMLET', 'DRAMATIS', 'PERSONAE', 'CLAUDIUS', 'king', ...]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data = [essayFile, randomFile, shakeFile]\n",
    "for file in data:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'abate',\n",
       " 'abatements',\n",
       " 'abhorred',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'abominably',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abridgement',\n",
       " 'abroad',\n",
       " 'absolute',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'accent',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidents',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accounted',\n",
       " 'accurst',\n",
       " 'accuse',\n",
       " 'ache',\n",
       " 'achievements',\n",
       " 'acquaint',\n",
       " 'acquaintance',\n",
       " 'acquire',\n",
       " 'acres',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'actively',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'adders',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'adheres',\n",
       " 'adieu',\n",
       " 'adjoin',\n",
       " 'admirable',\n",
       " 'admiration',\n",
       " 'admit',\n",
       " 'admittance',\n",
       " 'adoption',\n",
       " 'adulterate',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advantage',\n",
       " 'adventurous',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'aery',\n",
       " 'afar',\n",
       " 'afeard',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affectation',\n",
       " 'affection',\n",
       " 'affections',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afflicts',\n",
       " 'affrighted',\n",
       " 'afoot',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'ago',\n",
       " 'agreeing',\n",
       " 'ah',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airs',\n",
       " 'airy',\n",
       " 'alarm',\n",
       " 'alas',\n",
       " 'all',\n",
       " 'allegiance',\n",
       " 'alleys',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'aloof',\n",
       " 'already',\n",
       " 'also',\n",
       " 'altitude',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'ambassador',\n",
       " 'ambassadors',\n",
       " 'amber',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'amble',\n",
       " 'amen',\n",
       " 'amiss',\n",
       " 'amities',\n",
       " 'an',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'ancle',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angry',\n",
       " 'animals',\n",
       " 'annexment',\n",
       " 'annual',\n",
       " 'anoint',\n",
       " 'anon',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answerest',\n",
       " 'antic',\n",
       " 'anticipation',\n",
       " 'antique',\n",
       " 'any',\n",
       " 'apart',\n",
       " 'ape',\n",
       " 'apiece',\n",
       " 'apoplex',\n",
       " 'appal',\n",
       " 'apparel',\n",
       " 'apparition',\n",
       " 'appear',\n",
       " 'appears',\n",
       " 'appetite',\n",
       " 'applaud',\n",
       " 'appliance',\n",
       " 'appointment',\n",
       " 'apprehension',\n",
       " 'approve',\n",
       " 'appurtenance',\n",
       " 'apt',\n",
       " 'aptly',\n",
       " 'ardour',\n",
       " 'are',\n",
       " 'argal',\n",
       " 'argues',\n",
       " 'argument',\n",
       " 'aright',\n",
       " 'arithmetic',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'armour',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arraign',\n",
       " 'arrant',\n",
       " 'arras',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arrests',\n",
       " 'arrived',\n",
       " 'arrow',\n",
       " 'arrows',\n",
       " 'art',\n",
       " 'artery',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'artless',\n",
       " 'as',\n",
       " 'ashamed',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'aslant',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'assail',\n",
       " 'assault',\n",
       " 'assay',\n",
       " 'assays',\n",
       " 'assigns',\n",
       " 'assistant',\n",
       " 'associates',\n",
       " 'assume',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'assured',\n",
       " 'astonish',\n",
       " 'asunder',\n",
       " 'at',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attent',\n",
       " 'attractive',\n",
       " 'attribute',\n",
       " 'audience',\n",
       " 'audit',\n",
       " 'aught',\n",
       " 'augury',\n",
       " 'aunt',\n",
       " 'auspicious',\n",
       " 'author',\n",
       " 'authorities',\n",
       " 'avoid',\n",
       " 'avouch',\n",
       " 'awake',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awhile',\n",
       " 'awry',\n",
       " 'axe',\n",
       " 'ay',\n",
       " 'aye']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = set(file)\n",
    ">>> long_words = [w for w in V if w.startswith(\"a\")]\n",
    ">>> sorted(long_words)\n",
    "#a, abate, abatement, abhorred, ability, able, aboard, abominably,about,above,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e',\n",
       " 'each',\n",
       " 'eager',\n",
       " 'eale',\n",
       " 'ear',\n",
       " 'earnest',\n",
       " 'ears',\n",
       " 'earth',\n",
       " 'earthly',\n",
       " 'ease',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'easiness',\n",
       " 'easing',\n",
       " 'east',\n",
       " 'eastward',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eaten',\n",
       " 'eats',\n",
       " 'eclipse',\n",
       " 'ecstasy',\n",
       " 'edge',\n",
       " 'edified',\n",
       " 'effect',\n",
       " 'effects',\n",
       " 'egg',\n",
       " 'eight',\n",
       " 'eisel',\n",
       " 'either',\n",
       " 'elder',\n",
       " 'eldest',\n",
       " 'election',\n",
       " 'element',\n",
       " 'eleven',\n",
       " 'eloquent',\n",
       " 'else',\n",
       " 'em',\n",
       " 'embark',\n",
       " 'embrace',\n",
       " 'embracing',\n",
       " 'emperor',\n",
       " 'emphasis',\n",
       " 'empire',\n",
       " 'employ',\n",
       " 'employment',\n",
       " 'empty',\n",
       " 'emulate',\n",
       " 'en',\n",
       " 'enact',\n",
       " 'enactures',\n",
       " 'encompassment',\n",
       " 'encounter',\n",
       " 'encumber',\n",
       " 'end',\n",
       " 'endeavour',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'ends',\n",
       " 'endure',\n",
       " 'enemies',\n",
       " 'enemy',\n",
       " 'engaged',\n",
       " 'engineer',\n",
       " 'enlarged',\n",
       " 'enmity',\n",
       " 'enough',\n",
       " 'enseamed',\n",
       " 'enter',\n",
       " 'enterprise',\n",
       " 'enterprises',\n",
       " 'enters',\n",
       " 'entertainment',\n",
       " 'entrance',\n",
       " 'entreat',\n",
       " 'entreated',\n",
       " 'entreatments',\n",
       " 'entreaty',\n",
       " 'envenom',\n",
       " 'envious',\n",
       " 'enviously',\n",
       " 'envy',\n",
       " 'epitaph',\n",
       " 'equal',\n",
       " 'equivocation',\n",
       " 'er',\n",
       " 'erbears',\n",
       " 'erdoing',\n",
       " 'ere',\n",
       " 'ergrowth',\n",
       " 'erhanging',\n",
       " 'erhasty',\n",
       " 'erhear',\n",
       " 'ermaster',\n",
       " 'err',\n",
       " 'erring',\n",
       " 'errors',\n",
       " 'errule',\n",
       " 'erstep',\n",
       " 'ersways',\n",
       " 'erthrown',\n",
       " 'ertook',\n",
       " 'ertop',\n",
       " 'eruption',\n",
       " 'erweigh',\n",
       " 'erwhelm',\n",
       " 'es',\n",
       " 'escape',\n",
       " 'escoted',\n",
       " 'especial',\n",
       " 'especially',\n",
       " 'espials',\n",
       " 'essentially',\n",
       " 'estate',\n",
       " 'esteem',\n",
       " 'estimation',\n",
       " 'et',\n",
       " 'eternal',\n",
       " 'eterne',\n",
       " 'eternity',\n",
       " 'even',\n",
       " 'event',\n",
       " 'events',\n",
       " 'ever',\n",
       " 'evermore',\n",
       " 'every',\n",
       " 'evidence',\n",
       " 'evil',\n",
       " 'exact',\n",
       " 'exactly',\n",
       " 'exceed',\n",
       " 'excellence',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'exception',\n",
       " 'exchange',\n",
       " 'exclaim',\n",
       " 'excrements',\n",
       " 'excuse',\n",
       " 'exercise',\n",
       " 'exercises',\n",
       " 'exhort',\n",
       " 'exit',\n",
       " 'expectancy',\n",
       " 'expel',\n",
       " 'expend',\n",
       " 'expense',\n",
       " 'exploit',\n",
       " 'expostulate',\n",
       " 'express',\n",
       " 'extant',\n",
       " 'extent',\n",
       " 'exterior',\n",
       " 'extinct',\n",
       " 'extolment',\n",
       " 'extravagant',\n",
       " 'extremity',\n",
       " 'eyases',\n",
       " 'eye',\n",
       " 'eyelids',\n",
       " 'eyes']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = set(file)\n",
    ">>> long_words = [w for w in V if w.startswith(\"e\")]\n",
    ">>> sorted(long_words)\n",
    "#each, eager, eale, ear, earnest, ears, earth, earthly, ease, easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'ice',\n",
       " 'idle',\n",
       " 'idol',\n",
       " 'if',\n",
       " 'ignorance',\n",
       " 'ignorant',\n",
       " 'ild',\n",
       " 'ill',\n",
       " 'ills',\n",
       " 'illume',\n",
       " 'illusion',\n",
       " 'image',\n",
       " 'imagination',\n",
       " 'imaginations',\n",
       " 'imagine',\n",
       " 'imitated',\n",
       " 'immediate',\n",
       " 'immediately',\n",
       " 'imminent',\n",
       " 'immortal',\n",
       " 'impart',\n",
       " 'impartment',\n",
       " 'impasted',\n",
       " 'impatient',\n",
       " 'imperfections',\n",
       " 'imperial',\n",
       " 'impetuous',\n",
       " 'impious',\n",
       " 'implements',\n",
       " 'implorators',\n",
       " 'imponed',\n",
       " 'important',\n",
       " 'imports',\n",
       " 'importunate',\n",
       " 'importuned',\n",
       " 'importunity',\n",
       " 'imposthume',\n",
       " 'impotence',\n",
       " 'impotent',\n",
       " 'impress',\n",
       " 'impression',\n",
       " 'imputation',\n",
       " 'in',\n",
       " 'incapable',\n",
       " 'incensed',\n",
       " 'incest',\n",
       " 'incestuous',\n",
       " 'inch',\n",
       " 'inclination',\n",
       " 'inclined',\n",
       " 'inclining',\n",
       " 'incontinency',\n",
       " 'incorporal',\n",
       " 'incorpsed',\n",
       " 'incorrect',\n",
       " 'increase',\n",
       " 'indeed',\n",
       " 'indentures',\n",
       " 'index',\n",
       " 'indict',\n",
       " 'indifferent',\n",
       " 'indifferently',\n",
       " 'indirections',\n",
       " 'indiscretion',\n",
       " 'individable',\n",
       " 'indued',\n",
       " 'inexplicable',\n",
       " 'infallibly',\n",
       " 'infants',\n",
       " 'infect',\n",
       " 'infected',\n",
       " 'infinite',\n",
       " 'influence',\n",
       " 'inform',\n",
       " 'infusion',\n",
       " 'ingenious',\n",
       " 'inheritance',\n",
       " 'inheritor',\n",
       " 'inhibition',\n",
       " 'inky',\n",
       " 'inmost',\n",
       " 'innocent',\n",
       " 'innovation',\n",
       " 'inoculate',\n",
       " 'inquire',\n",
       " 'insert',\n",
       " 'insinuation',\n",
       " 'insolence',\n",
       " 'instance',\n",
       " 'instances',\n",
       " 'instant',\n",
       " 'instantly',\n",
       " 'instructs',\n",
       " 'instrument',\n",
       " 'instrumental',\n",
       " 'intend',\n",
       " 'intent',\n",
       " 'intents',\n",
       " 'inter',\n",
       " 'interim',\n",
       " 'interpret',\n",
       " 'intil',\n",
       " 'into',\n",
       " 'intruding',\n",
       " 'inurn',\n",
       " 'inventorially',\n",
       " 'inventors',\n",
       " 'investments',\n",
       " 'invisible',\n",
       " 'invite',\n",
       " 'invites',\n",
       " 'invulnerable',\n",
       " 'inward',\n",
       " 'is',\n",
       " 'issue',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = set(file)\n",
    ">>> long_words = [w for w in V if w.startswith(\"i\")]\n",
    ">>> sorted(long_words)\n",
    "#ice, idle, idol, if, ignorance, ignornt, ild, ill, ills, illume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o',\n",
       " 'oath',\n",
       " 'oaths',\n",
       " 'obedience',\n",
       " 'obey',\n",
       " 'obeys',\n",
       " 'object',\n",
       " 'objects',\n",
       " 'obligation',\n",
       " 'oblivion',\n",
       " 'obscure',\n",
       " 'obsequies',\n",
       " 'obsequious',\n",
       " 'observance',\n",
       " 'observant',\n",
       " 'observation',\n",
       " 'observe',\n",
       " 'observed',\n",
       " 'observers',\n",
       " 'obstinate',\n",
       " 'occasion',\n",
       " 'occasions',\n",
       " 'occulted',\n",
       " 'occurrents',\n",
       " 'ocean',\n",
       " 'odd',\n",
       " 'odds',\n",
       " 'of',\n",
       " 'off',\n",
       " 'offal',\n",
       " 'offence',\n",
       " 'offences',\n",
       " 'offend',\n",
       " 'offended',\n",
       " 'offendendo',\n",
       " 'offender',\n",
       " 'offends',\n",
       " 'offer',\n",
       " 'office',\n",
       " 'officers',\n",
       " 'oft',\n",
       " 'often',\n",
       " 'old',\n",
       " 'omen',\n",
       " 'ominous',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'ope',\n",
       " 'oped',\n",
       " 'open',\n",
       " 'operant',\n",
       " 'opinion',\n",
       " 'opinions',\n",
       " 'opposed',\n",
       " 'opposing',\n",
       " 'opposite',\n",
       " 'opposites',\n",
       " 'opposition',\n",
       " 'oppress',\n",
       " 'oppression',\n",
       " 'oppressor',\n",
       " 'or',\n",
       " 'orb',\n",
       " 'orbed',\n",
       " 'orchard',\n",
       " 'order',\n",
       " 'orderly',\n",
       " 'ordinant',\n",
       " 'ordnance',\n",
       " 'ore',\n",
       " 'organ',\n",
       " 'origin',\n",
       " 'orisons',\n",
       " 'ostentation',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourself',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outbreak',\n",
       " 'outface',\n",
       " 'outlive',\n",
       " 'outlives',\n",
       " 'outrageous',\n",
       " 'outstretched',\n",
       " 'outward',\n",
       " 'over',\n",
       " 'overcame',\n",
       " 'overcome',\n",
       " 'overdone',\n",
       " 'overlooked',\n",
       " 'overpeering',\n",
       " 'overthrown',\n",
       " 'owl',\n",
       " 'own',\n",
       " 'owner',\n",
       " 'ownself']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = set(file)\n",
    ">>> long_words = [w for w in V if w.startswith(\"o\")]\n",
    ">>> sorted(long_words)\n",
    "#oath, oaths, obedience, obey, obeys, object, objects, obligation, oblivion, obscure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ubique',\n",
       " 'ugly',\n",
       " 'ulcer',\n",
       " 'ulcerous',\n",
       " 'umbrage',\n",
       " 'unanel',\n",
       " 'unbated',\n",
       " 'unbraced',\n",
       " 'uncharge',\n",
       " 'uncle',\n",
       " 'unction',\n",
       " 'uncurrent',\n",
       " 'under',\n",
       " 'undergo',\n",
       " 'understand',\n",
       " 'understanding',\n",
       " 'undertake',\n",
       " 'undertakings',\n",
       " 'undiscover',\n",
       " 'undo',\n",
       " 'uneffectual',\n",
       " 'unequal',\n",
       " 'unfellowed',\n",
       " 'unfledged',\n",
       " 'unfold',\n",
       " 'unforced',\n",
       " 'unfortified',\n",
       " 'ungalled',\n",
       " 'ungored',\n",
       " 'ungracious',\n",
       " 'unhappily',\n",
       " 'unholy',\n",
       " 'unimproved',\n",
       " 'union',\n",
       " 'university',\n",
       " 'unkennel',\n",
       " 'unkind',\n",
       " 'unknowing',\n",
       " 'unknown',\n",
       " 'unless',\n",
       " 'unlimited',\n",
       " 'unmanly',\n",
       " 'unmannerly',\n",
       " 'unmask',\n",
       " 'unmaster',\n",
       " 'unmatch',\n",
       " 'unnatural',\n",
       " 'unnerved',\n",
       " 'unpack',\n",
       " 'unpolluted',\n",
       " 'unpregnant',\n",
       " 'unprevailing',\n",
       " 'unprofitable',\n",
       " 'unproportioned',\n",
       " 'unreclaimed',\n",
       " 'unrighteous',\n",
       " 'unripe',\n",
       " 'unsanctified',\n",
       " 'unsatisfied',\n",
       " 'unschool',\n",
       " 'unseal',\n",
       " 'unseen',\n",
       " 'unshaken',\n",
       " 'unshaped',\n",
       " 'unsinew',\n",
       " 'unskilful',\n",
       " 'unsmirched',\n",
       " 'unsure',\n",
       " 'untimely',\n",
       " 'unto',\n",
       " 'unused',\n",
       " 'unvalued',\n",
       " 'unwatch',\n",
       " 'unweeded',\n",
       " 'unwholesome',\n",
       " 'unwilling',\n",
       " 'unworthiest',\n",
       " 'unworthy',\n",
       " 'unwrung',\n",
       " 'unyoke',\n",
       " 'up',\n",
       " 'uphoarded',\n",
       " 'upon',\n",
       " 'upshot',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'uses',\n",
       " 'usual',\n",
       " 'usurp',\n",
       " 'utter',\n",
       " 'utterance']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = set(file)\n",
    ">>> long_words = [w for w in V if w.startswith(\"u\")]\n",
    ">>> sorted(long_words)\n",
    "#ubique,ugly,ulcer,ulcerous,umbrage,unanel,unbated,unbraced,uncharge,uncle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. A stemmed version of the longest sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-403-41e71128b640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlongest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-403-41e71128b640>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlongest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/stem/porter.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLTK_EXTENSIONS\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(t) for t in longest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
